{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89c3939e",
      "metadata": {
        "id": "89c3939e"
      },
      "source": [
        "### Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d9f2ce14",
      "metadata": {
        "id": "d9f2ce14",
        "outputId": "9ba0acdc-305e-4e61-d170-800bff0dd486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hi, this is an example of string with lowercase and upper case.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"Hi, This is an example of string with lowercase and upper CASE.\".lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bcc058bb",
      "metadata": {
        "id": "bcc058bb",
        "outputId": "4efe9dd1-acc7-4959-bb5a-7d2da9a82c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HI, THIS IS AN EXAMPLE OF STRING WITH LOWERCASE AND UPPER CASE.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"Hi, This is an example of string with lowercase and upper CASE.\".upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "271e5635",
      "metadata": {
        "id": "271e5635"
      },
      "source": [
        "### Rimozione della punteggiatura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "793b518a",
      "metadata": {
        "id": "793b518a",
        "outputId": "d1a526dc-b682-4f9c-d0ac-29e185c39201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi  I started studying natural language processing with this beautiful course offered by ProfessionAI \n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "sentence = \"Hi, I started studying natural language processing with this beautiful course offered by ProfessionAI.\"\n",
        "for c in string.punctuation:\n",
        "    sentence = sentence.replace(c, \" \")\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80ed9b4f",
      "metadata": {
        "id": "80ed9b4f"
      },
      "source": [
        "### STEMMING - mantiene le radici delle parole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "19f39a63",
      "metadata": {
        "id": "19f39a63"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3779cec8",
      "metadata": {
        "id": "3779cec8",
        "outputId": "4ccfbabf-829b-4041-bb5e-35b634a7f08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'civil'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ps = PorterStemmer()\n",
        "word = (\"civilization\")\n",
        "ps.stem(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe5e084d",
      "metadata": {
        "id": "fe5e084d",
        "outputId": "fbffd3e4-a045-46f1-a2bd-b24027218bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i start studi natur languag process with thi beauti cours offer by professionai.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sentence = \"I started studying natural language processing with this beautiful course offered by ProfessionAI.\"\n",
        "stemmed_sentence = ' '.join(ps.stem(word) for word in sentence.split())\n",
        "stemmed_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9df027b",
      "metadata": {
        "id": "b9df027b"
      },
      "source": [
        "### Lemmatization - porta i verbi all'infinito. da forma flessa a canonica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a9ce7d7e",
      "metadata": {
        "id": "a9ce7d7e",
        "outputId": "e4488a7c-85de-42d0-f138-5e1123e5e4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ca01596c",
      "metadata": {
        "id": "ca01596c",
        "outputId": "3c9676d0-1340-4936-ff2e-0701f409af23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I I\n",
            "started start\n",
            "studying study\n",
            "natural natural\n",
            "language language\n",
            "processing processing\n",
            "with with\n",
            "this this\n",
            "beautiful beautiful\n",
            "course course\n",
            "offered offer\n",
            "by by\n",
            "ProfessionAI ProfessionAI\n",
            ". .\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentence = \"I started studying natural language processing with this beautiful course offered by ProfessionAI.\"\n",
        "doc = nlp(sentence)\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c58f08",
      "metadata": {
        "id": "51c58f08"
      },
      "source": [
        "### Rimozione stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5254ae9a",
      "metadata": {
        "id": "5254ae9a"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "english_stopwords = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f775eb90",
      "metadata": {
        "id": "f775eb90"
      },
      "outputs": [],
      "source": [
        "english_stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3862190e",
      "metadata": {
        "id": "3862190e"
      },
      "outputs": [],
      "source": [
        "sentence = \"I started studying natural language processing with this beautiful course offered by ProfessionAI.\"\n",
        "sentence_no_stopwords = \" \".join(word for word in sentence.split() if word not in english_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e65c62",
      "metadata": {
        "id": "78e65c62"
      },
      "outputs": [],
      "source": [
        "sentence_no_stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32770196",
      "metadata": {
        "id": "32770196"
      },
      "source": [
        "## Rimozione dei numeri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6758953",
      "metadata": {
        "id": "a6758953"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "s = \"In this sentence there are 3 numbers, 2 and 1234\"\n",
        "print(re.sub('\\d', '', s))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc781e7",
      "metadata": {
        "id": "cbc781e7"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54922bf",
      "metadata": {
        "id": "f54922bf"
      },
      "outputs": [],
      "source": [
        "sentence = \"I started studying natural language processing with this beautiful course offered by ProfessionAI.\"\n",
        "tokenized_sentence = sentence.split()\n",
        "tokenized_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b3e0dc",
      "metadata": {
        "id": "d4b3e0dc"
      },
      "source": [
        "## Creiamo la funzione che pulisce il testo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febe8f02",
      "metadata": {
        "id": "febe8f02"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "english_stopwords = stopwords.words('english')\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "def data_cleaner(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    for c in string.punctuation:\n",
        "        sentence = sentence.replace(c, \" \")\n",
        "    document = nlp(sentence)\n",
        "    sentence = ' '.join(token.lemma_ for token in document)\n",
        "    sentence = ' '.join(word for word in sentence.split() if word not in english_stopwords)\n",
        "    sentence = re.sub('\\d', '', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd4831f",
      "metadata": {
        "id": "6fd4831f"
      },
      "outputs": [],
      "source": [
        "data_cleaner('Hi, this is a phrase used to test our data cleaning method!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39501c15",
      "metadata": {
        "id": "39501c15"
      },
      "source": [
        "# Importiamo il dataset\n",
        "##### Per testare le funzioni appena descritte, importiamo il dataset 20newsgroups, un dataset che è possibile scaricare utilizzando la libreria scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1c7993",
      "metadata": {
        "id": "5a1c7993"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599b91c9",
      "metadata": {
        "id": "599b91c9"
      },
      "outputs": [],
      "source": [
        "newsgroups_train.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34151af",
      "metadata": {
        "id": "a34151af"
      },
      "outputs": [],
      "source": [
        "dataset = newsgroups_train['data']\n",
        "target = newsgroups_train['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe1de53",
      "metadata": {
        "id": "8fe1de53"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9484d86a",
      "metadata": {
        "id": "9484d86a"
      },
      "outputs": [],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cda9cc0",
      "metadata": {
        "id": "1cda9cc0"
      },
      "outputs": [],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522159e2",
      "metadata": {
        "id": "522159e2"
      },
      "outputs": [],
      "source": [
        "len(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769f74ae",
      "metadata": {
        "id": "769f74ae"
      },
      "outputs": [],
      "source": [
        "cleaned_dataset = [data_cleaner(doc) for doc in dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b730a4e0",
      "metadata": {
        "id": "b730a4e0"
      },
      "outputs": [],
      "source": [
        "len(cleaned_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d761a6",
      "metadata": {
        "id": "36d761a6"
      },
      "outputs": [],
      "source": [
        "cleaned_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69dd5f99",
      "metadata": {
        "id": "69dd5f99"
      },
      "outputs": [],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594be8f2",
      "metadata": {
        "id": "594be8f2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame({'data':cleaned_dataset,'target':target}).to_csv('datasets/Lezione_1-data_cleaning/dataset.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f736825",
      "metadata": {
        "id": "9f736825"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}